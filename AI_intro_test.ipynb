{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d28365-59fc-4e54-958a-f66891be56d8",
   "metadata": {},
   "source": [
    "We will explore linear regression in this exercise. We will train a model to predict the sale price depending on ground square feet for houses.\n",
    "\n",
    "We first load the necessary tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b0e46-5b9d-4b06-aae5-9f6a7693b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipydis\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d995bfa-be61-49c8-9a21-455c3f15d3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "We use Pandas to read the data file which is stored as Comma Separated Values (CSV) and print the column labels. CSV files are similar to excel sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5bf2cc-091c-419c-8827-a6b26460fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('slimmed_realestate_data.csv')\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffea58-3062-44cc-be3a-eafec267ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(x='GrLivArea', y='SalePrice',style='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58758f4c-c935-4323-976f-c7e4e0c8b715",
   "metadata": {},
   "source": [
    "x will be our above ground square footage and y will be the sale price. In our equations we have a few different values we need, such as \n",
    "n, which is just the number of data points we have.\n",
    "\n",
    "Note: we also need to convert the Pandas data formats (in this case a Series) to Numpy data formats using the to_numpy() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6d6876-7f55-451b-a125-1951a6b41b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8303ec8-88bf-450e-b880-3e120ccb1101",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['GrLivArea'].to_numpy()\n",
    "y = data['SalePrice'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca59641-5d9c-48d7-94a9-be40664fb348",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_xy = np.sum(x*y)\n",
    "sum_x = np.sum(x)\n",
    "sum_y = np.sum(y)\n",
    "sum_x2 = np.sum(x*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f139df-5a2f-4fe1-8b37-d70237ac7fe2",
   "metadata": {},
   "source": [
    "The denominator in the equations to calculate m & b (please refer to lecture notes on regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a58468-cdbf-4f6b-b8fc-c4c9551ce69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = n * sum_x2 - sum_x * sum_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c60f1-43fb-4231-8318-db1c7fb3b3c0",
   "metadata": {},
   "source": [
    "Now, we compute m & b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4b53b-e966-4d48-884c-563f7300db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = (n * sum_xy - sum_x * sum_y) / denominator\n",
    "b = (sum_y * sum_x2 - sum_x * sum_xy) / denominator\n",
    "print('y = %f * x + %f' % (m,b))\n",
    "\n",
    "# saving these for later comparison\n",
    "m_calc = m\n",
    "b_calc = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b8243-8e1c-4e0f-bf1d-74e39433c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(x,y,m,b,plt = plt):\n",
    "   # plot our data points with 'bo' = blue circles\n",
    "   plt.plot(x,y,'bo')\n",
    "   # create the line based on our linear fit\n",
    "   # first we need to make x points\n",
    "   # the 'arange' function generates points between two limits (min,max)\n",
    "   linear_x = np.arange(x.min(),x.max())\n",
    "   # now we use our fit parameters to calculate the y points based on our x points\n",
    "   linear_y = linear_x * m + b\n",
    "   # plot the linear points using 'r-' = red line\n",
    "   plt.plot(linear_x,linear_y,'g-',label='fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41548b47-6510-48df-bdcc-3874091f7763",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(x,y,m,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36103a5e-6329-4dc8-ab24-476dc978c08e",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent (SGD) is a popular optimization algorithm used to train machine learning models, particularly neural networks. It is an iterative method for optimizing a loss function that we get to define. \n",
    "\n",
    "In our example, the model is how house prices vary based on house size. We know our system is roughly driven by a linear function: y= mx + b, and we need to figure out m & b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95418cf0-6640-4a47-9a89-c2ab88951c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x,m,b):\n",
    "   return m * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004fea26-a28a-4e17-b3c6-423e7cda89ba",
   "metadata": {},
   "source": [
    "Let's create the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e514e6-abc9-40f5-8862-bf48ed1ac181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x,y,m,b):\n",
    "   y_predicted = model(x,m,b)\n",
    "   return np.power( y - y_predicted, 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8b2c17-89fe-4198-82a0-df66bf3c06bd",
   "metadata": {},
   "source": [
    "Let's now update m & b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb41feb-3a4d-4859-95ea-84083625f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updated_m(x,y,m,b,learning_rate):\n",
    "   dL_dm = - 2 * x * (y - model(x,m,b))\n",
    "   dL_dm = np.mean(dL_dm)\n",
    "   return m - learning_rate * dL_dm\n",
    "\n",
    "def updated_b(x,y,m,b,learning_rate):\n",
    "   dL_db = - 2 * (y - model(x,m,b))\n",
    "   dL_db = np.mean(dL_db)\n",
    "   return b - learning_rate * dL_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dd43bb-d943-414c-994e-9818259a8273",
   "metadata": {},
   "source": [
    "Let's now put it all together and train our model.\n",
    "\n",
    "We can now randomly select our initial slope(m) and intercept(b):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1062f0d-3351-4793-a79e-8de7e8196292",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 5.\n",
    "b = 1000.\n",
    "print('y_i = %.2f * x + %.2f' % (m,b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6de49a-9c0e-4af5-87de-ff93f0e027db",
   "metadata": {},
   "source": [
    "Then we can calculate our Loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72cf76-7c77-4390-85e1-7211d88bbd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = loss(x,y,m,b)\n",
    "print('first 10 loss values: ',l[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e422d991-068c-4344-8783-869ef95358ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-9\n",
    "m = updated_m(x,y,m,b,learning_rate)\n",
    "b = updated_b(x,y,m,b,learning_rate)\n",
    "print('y_i = %.2f * x + %.2f     previously calculated: y_i = %.2f * x + %.2f' % (m,b,m_calc,b_calc))\n",
    "plot_data(x,y,m,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6598bed7-b911-4e03-a136-4962f6b620ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our initial slope and intercept\n",
    "m = 5.\n",
    "b = 1000.\n",
    "#batch_size = 512\n",
    "# set a learning rate for each parameter\n",
    "learning_rate_m = 1e-7\n",
    "learning_rate_b = 1e-1\n",
    "# use these to plot our progress over time\n",
    "loss_history = []\n",
    "# convert panda data to numpy arrays, one for the \"Ground Living Area\" and one for \"Sale Price\"\n",
    "data_x = data['GrLivArea'].to_numpy()\n",
    "data_y = data['SalePrice'].to_numpy()\n",
    "#Sample data randomly in batches of size batch_size\n",
    "#data_batch = data.sample(batch_size)\n",
    "#data_x = data_batch['GrLivArea'].to_numpy()\n",
    "#data_y = data_batch['SalePrice'].to_numpy()\n",
    "# we run our loop N times\n",
    "#loop_N = 30 * len(data)//batch_size\n",
    "loop_N = 30\n",
    "for i in range(loop_N):\n",
    "   # update our slope and intercept based on the current values\n",
    "   m = updated_m(data_x,data_y,m,b,learning_rate_m)\n",
    "   b = updated_b(data_x,data_y,m,b,learning_rate_b)\n",
    "\n",
    "   # calculate the loss value\n",
    "   loss_value = np.mean(loss(data_x,data_y,m,b))\n",
    "\n",
    "   # keep a history of our loss values\n",
    "   loss_history.append(loss_value)\n",
    "\n",
    "   # print our progress\n",
    "   print('[%03d]  dy_i = %.2f * x + %.2f     previously calculated: y_i = %.2f * x + %.2f    loss: %f' % (i,m,b,m_calc,b_calc,loss_value))\n",
    "\n",
    "   # close/delete previous plots\n",
    "   plt.close('all')\n",
    "\n",
    "   # create a 1 by 2 plot grid\n",
    "   fig,ax = plt.subplots(1,2,figsize=(18,6),dpi=80)\n",
    "   # lot our usual output\n",
    "   plot_data(data_x,data_y,m,b,ax[0])\n",
    "\n",
    "   # here we also plot the calculated linear fit for comparison\n",
    "   line_x = np.arange(data_x.min(),data_x.max())\n",
    "   line_y = line_x * m_calc + b_calc\n",
    "   ax[0].plot(line_x,line_y,'b-',label='calculated')\n",
    "   # add a legend to the plot and x/y labels\n",
    "   ax[0].legend()\n",
    "   ax[0].set_xlabel('square footage')\n",
    "   ax[0].set_ylabel('sale price')\n",
    "\n",
    "   # plot the loss\n",
    "   loss_x = np.arange(0,len(loss_history))\n",
    "   loss_y = np.asarray(loss_history)\n",
    "   ax[1].plot(loss_x,loss_y, 'o-')\n",
    "   ax[1].set_yscale('log')\n",
    "   ax[1].set_xlabel('loop step')\n",
    "   ax[1].set_ylabel('loss')\n",
    "   plt.show()\n",
    "   # gives us time to see the plot\n",
    "   time.sleep(2.5)\n",
    "   # clears the plot when the next plot is ready to show.\n",
    "   ipydis.clear_output(wait=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22cab1a-7398-4be0-bc96-40eefdff0a53",
   "metadata": {},
   "source": [
    "Exercise: Vary the learning rates for m & b to see  the changes in your output. Vary the numbers learning_rate_m = 1e-7, learning_rate_b = 1e-1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
